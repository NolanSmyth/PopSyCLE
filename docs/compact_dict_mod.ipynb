{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from popsycle import synthetic\n",
    "\n",
    "import copy\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at comp_dict directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"l0b0\": shape (188784,), type \"|V232\">\n"
     ]
    }
   ],
   "source": [
    "file_path = 'example_ffp.h5'\n",
    "with h5py.File(file_path, 'r') as f:\n",
    "    print(f['l0b0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are the keys inside the lat/long bins\n",
    "phys_keys = ['zams_mass', 'mass', 'px', 'py', 'pz', 'vx', 'vy', 'vz', 'age',\n",
    "       'popid', 'exbv', 'glat', 'glon', 'mbol', 'grav', 'teff', 'feh',\n",
    "       'rad', 'rem_id', 'obj_id', 'ubv_J', 'ubv_H', 'ubv_K', 'ubv_U',\n",
    "       'ubv_I', 'ubv_B', 'ubv_V', 'ubv_R', 'vr', 'mu_b', 'mu_lcosb']\n",
    "\n",
    "#this is to keep track of which bin each star came from\n",
    "phys_keys.append('bin_name')\n",
    "\n",
    "#these keys don't contain stars so ignore them in the loop creating the df\n",
    "ignored_keys = {'add_pbh', 'lat_bin_edges', 'long_bin_edges'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_from_popsyn(file_path = 'example_ffp.h5'):\n",
    "    '''\n",
    "    takes the compact object dictionary after PBHs are injected and returns\n",
    "    a pandas DataFrame of all stars and their attributes\n",
    "    '''\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        \n",
    "        df = pd.DataFrame(columns=phys_keys)\n",
    "\n",
    "        for key in list(f.keys()):\n",
    "            if key not in ignored_keys:\n",
    "                num_stars = len(np.array(f[key]))\n",
    "\n",
    "                #0 is a physical quantitiy so initialize with nans\n",
    "                sub_arr = np.full((num_stars, len(phys_keys)), np.nan)\n",
    "                #loop through all the stars in this bin and add their attributes to an array\n",
    "                for i, star in enumerate(np.array(f[key])):\n",
    "                    sub_arr[i][:-1] = list(star)\n",
    "                #add the attributes of all the stars from this bin to the master dataframe\n",
    "                sub_df = pd.DataFrame(sub_arr, columns=phys_keys)\n",
    "                sub_df['bin_name'] = key\n",
    "                df = pd.concat([df, sub_df]) \n",
    "    \n",
    "    return df\n",
    "\n",
    "def sample_ffp_mass(N_ffps: int) -> np.array:\n",
    "    '''\n",
    "    This is a dummy function currently. Will want to sample some distribution of masses for the ffps.\n",
    "    For now, return an array of length N_ffps with fixed mass value in units of solar masses\n",
    "    '''\n",
    "\n",
    "    #Jupiter is about 1e-3 solar masses\n",
    "    return np.ones(N_ffps) * 1e-3\n",
    "\n",
    "def set_ffp_masses(df_ffps: pd.DataFrame) :\n",
    "    '''\n",
    "    Modifies the input dataframe to overwrite the masses of the ffps.\n",
    "    '''\n",
    "    N_objects = df_ffps.shape[0]\n",
    "    masses = sample_ffp_mass(N_objects)\n",
    "    df_ffps['mass'] = masses\n",
    "    #PopSyCLE sets Zero age main sequence mass,zams_mass, equal to mass for PBHs. \n",
    "    #Following this convention for ffps\n",
    "    df_ffps['zams_mass'] = masses\n",
    "\n",
    "\n",
    "def set_ffp_photometry(df_ffps: pd.DataFrame):\n",
    "    '''\n",
    "    Modifies the input dataframe to overwrite the photometry of the ffps.\n",
    "    '''\n",
    "    N_objects = df_ffps.shape[0]\n",
    "    photometry_ffps = np.zeros(N_objects)\n",
    "\n",
    "    df_ffps['ubv_J'] = photometry_ffps\n",
    "    df_ffps['ubv_H'] = photometry_ffps\n",
    "    df_ffps['ubv_K'] = photometry_ffps\n",
    "    df_ffps['ubv_U'] = photometry_ffps\n",
    "    df_ffps['ubv_I'] = photometry_ffps\n",
    "    df_ffps['ubv_B'] = photometry_ffps\n",
    "    df_ffps['ubv_V'] = photometry_ffps\n",
    "    df_ffps['ubv_R'] = photometry_ffps\n",
    "\n",
    "def set_ffp_rem_id(df_ffps: pd.DataFrame):\n",
    "    '''\n",
    "    Modifies the input dataframe to overwrite the remnant id of the ffps.\n",
    "    '''\n",
    "    N_objects = df_ffps.shape[0]\n",
    "    #pbhs are highest remnant id implemented in popsycle so far so set ffps to 105\n",
    "    rem_ids = np.ones(N_objects) * 105\n",
    "    df_ffps['rem_id'] = rem_ids\n",
    "\n",
    "def set_ffp_pop_id(df_ffps: pd.DataFrame):\n",
    "    '''\n",
    "    Modifies the input dataframe to overwrite the pop id of the ffps.\n",
    "    Set it to 10 since this is what is done for PBHs\n",
    "    '''\n",
    "    N_objects = df_ffps.shape[0]\n",
    "    #Population ID (e.g. Disk, Halo, Bulge. See https://galaxia.sourceforge.net/Galaxia3pub.html for details) 'popid'.\n",
    "    pop_ids = np.ones(N_objects) * 10\n",
    "\n",
    "def set_ffp_misc(df_ffps: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Modifies the input dataframe to overwrite some miscilanious attributes of the ffps\n",
    "    that are not relevant for us. Set them to NaNs (this is what is done for PBHs I believe)\n",
    "    '''\n",
    "\n",
    "    # Bolometric magnitude: mbol, \n",
    "    # Surface gravity: grav,\n",
    "    # Metalicity: feh,\n",
    "    # log(age/yr): 'age',\n",
    "    # Effective temperature: teff\n",
    "    # Galactic Extinsion 'exbv'\n",
    "\n",
    "\n",
    "    N_objects = df_ffps.shape[0]\n",
    "    misc_ffps_nans = np.full(N_objects, np.NaN)\n",
    "   \n",
    "    df_ffps['mbol'] = misc_ffps_nans\n",
    "    df_ffps['grav'] = misc_ffps_nans\n",
    "    df_ffps['feh'] = misc_ffps_nans\n",
    "    df_ffps['age'] = misc_ffps_nans\n",
    "    df_ffps['teff'] = misc_ffps_nans\n",
    "    df_ffps['exbv'] = misc_ffps_nans\n",
    "\n",
    "\n",
    "def inject_ffp_params(df_ffps: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Modifies the input dataframe to overwrite all relevant parameters for ffps\n",
    "    '''\n",
    "    set_ffp_masses(df_ffps)\n",
    "    set_ffp_photometry(df_ffps)\n",
    "    set_ffp_rem_id(df_ffps)\n",
    "    set_ffp_misc(df_ffps)\n",
    "    set_ffp_pop_id(df_ffps)\n",
    "\n",
    "    #todo\n",
    "    #Heliocentric velocities (in km/s): 'vx', 'vy', 'vz',\n",
    "    #Radial velocity and proper motions: 'vr', 'mu_b', 'mu_lcosb'\n",
    "    # Galactic positions 'rad', 'glat', 'glon'\n",
    "    # Heliocentric positions: 'px', 'py', 'pz', \n",
    "    # positions related by:\n",
    "    # comp_helio = synthetic.galactic_to_heliocentric(\n",
    "    #             comp_dict[\"rad\"], comp_dict[\"glat\"], comp_dict[\"glon\"]\n",
    "    #         )\n",
    "    #         comp_dict[\"px\"], comp_dict[\"py\"], comp_dict[\"pz\"] = comp_helio\n",
    "    # Object number within given bin: obj_id - Don't think we care about this but should revisit later - obj_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = make_df_from_popsyn('example_ffp.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zams_mass</th>\n",
       "      <th>mass</th>\n",
       "      <th>px</th>\n",
       "      <th>py</th>\n",
       "      <th>pz</th>\n",
       "      <th>vx</th>\n",
       "      <th>vy</th>\n",
       "      <th>vz</th>\n",
       "      <th>age</th>\n",
       "      <th>popid</th>\n",
       "      <th>...</th>\n",
       "      <th>ubv_K</th>\n",
       "      <th>ubv_U</th>\n",
       "      <th>ubv_I</th>\n",
       "      <th>ubv_B</th>\n",
       "      <th>ubv_V</th>\n",
       "      <th>ubv_R</th>\n",
       "      <th>vr</th>\n",
       "      <th>mu_b</th>\n",
       "      <th>mu_lcosb</th>\n",
       "      <th>bin_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.503571</td>\n",
       "      <td>0.503571</td>\n",
       "      <td>3.631762</td>\n",
       "      <td>0.062991</td>\n",
       "      <td>-0.065598</td>\n",
       "      <td>-20.581390</td>\n",
       "      <td>-24.072226</td>\n",
       "      <td>-12.524226</td>\n",
       "      <td>5.827383</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.792072</td>\n",
       "      <td>11.798287</td>\n",
       "      <td>7.600787</td>\n",
       "      <td>10.721358</td>\n",
       "      <td>9.466644</td>\n",
       "      <td>8.552930</td>\n",
       "      <td>-20.766177</td>\n",
       "      <td>-0.748646</td>\n",
       "      <td>-1.375852</td>\n",
       "      <td>l0b0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.393893</td>\n",
       "      <td>0.393893</td>\n",
       "      <td>4.790543</td>\n",
       "      <td>0.082235</td>\n",
       "      <td>-0.086362</td>\n",
       "      <td>-18.358408</td>\n",
       "      <td>-10.715219</td>\n",
       "      <td>-3.930184</td>\n",
       "      <td>5.544013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.421209</td>\n",
       "      <td>12.853517</td>\n",
       "      <td>8.287896</td>\n",
       "      <td>11.697989</td>\n",
       "      <td>10.366171</td>\n",
       "      <td>9.388461</td>\n",
       "      <td>-18.465815</td>\n",
       "      <td>-0.187513</td>\n",
       "      <td>-0.457441</td>\n",
       "      <td>l0b0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.095672</td>\n",
       "      <td>0.095672</td>\n",
       "      <td>5.375013</td>\n",
       "      <td>0.092805</td>\n",
       "      <td>-0.097811</td>\n",
       "      <td>7.669304</td>\n",
       "      <td>-35.641441</td>\n",
       "      <td>-15.736011</td>\n",
       "      <td>5.257884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.649642</td>\n",
       "      <td>18.339668</td>\n",
       "      <td>11.017556</td>\n",
       "      <td>16.098106</td>\n",
       "      <td>14.173828</td>\n",
       "      <td>12.747360</td>\n",
       "      <td>7.337969</td>\n",
       "      <td>-0.611782</td>\n",
       "      <td>-1.402376</td>\n",
       "      <td>l0b0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.103781</td>\n",
       "      <td>0.103781</td>\n",
       "      <td>1.381481</td>\n",
       "      <td>0.024024</td>\n",
       "      <td>-0.025084</td>\n",
       "      <td>-18.424522</td>\n",
       "      <td>-6.588330</td>\n",
       "      <td>-14.462896</td>\n",
       "      <td>6.750011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.581558</td>\n",
       "      <td>17.990839</td>\n",
       "      <td>10.907817</td>\n",
       "      <td>15.848731</td>\n",
       "      <td>13.963803</td>\n",
       "      <td>12.583215</td>\n",
       "      <td>-18.270712</td>\n",
       "      <td>-2.257165</td>\n",
       "      <td>-0.956019</td>\n",
       "      <td>l0b0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.146732</td>\n",
       "      <td>0.146732</td>\n",
       "      <td>2.826867</td>\n",
       "      <td>0.049280</td>\n",
       "      <td>-0.051460</td>\n",
       "      <td>-30.147104</td>\n",
       "      <td>-21.643343</td>\n",
       "      <td>-0.324761</td>\n",
       "      <td>6.945432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.443503</td>\n",
       "      <td>16.352642</td>\n",
       "      <td>10.557643</td>\n",
       "      <td>14.792372</td>\n",
       "      <td>13.177802</td>\n",
       "      <td>12.001276</td>\n",
       "      <td>-30.508786</td>\n",
       "      <td>-0.065583</td>\n",
       "      <td>-1.574057</td>\n",
       "      <td>l0b0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   zams_mass      mass        px        py        pz         vx         vy  \\\n",
       "0   0.503571  0.503571  3.631762  0.062991 -0.065598 -20.581390 -24.072226   \n",
       "1   0.393893  0.393893  4.790543  0.082235 -0.086362 -18.358408 -10.715219   \n",
       "2   0.095672  0.095672  5.375013  0.092805 -0.097811   7.669304 -35.641441   \n",
       "3   0.103781  0.103781  1.381481  0.024024 -0.025084 -18.424522  -6.588330   \n",
       "4   0.146732  0.146732  2.826867  0.049280 -0.051460 -30.147104 -21.643343   \n",
       "\n",
       "          vz       age  popid  ...     ubv_K      ubv_U      ubv_I      ubv_B  \\\n",
       "0 -12.524226  5.827383    0.0  ...  5.792072  11.798287   7.600787  10.721358   \n",
       "1  -3.930184  5.544013    0.0  ...  6.421209  12.853517   8.287896  11.697989   \n",
       "2 -15.736011  5.257884    0.0  ...  8.649642  18.339668  11.017556  16.098106   \n",
       "3 -14.462896  6.750011    0.0  ...  8.581558  17.990839  10.907817  15.848731   \n",
       "4  -0.324761  6.945432    0.0  ...  8.443503  16.352642  10.557643  14.792372   \n",
       "\n",
       "       ubv_V      ubv_R         vr      mu_b  mu_lcosb  bin_name  \n",
       "0   9.466644   8.552930 -20.766177 -0.748646 -1.375852      l0b0  \n",
       "1  10.366171   9.388461 -18.465815 -0.187513 -0.457441      l0b0  \n",
       "2  14.173828  12.747360   7.337969 -0.611782 -1.402376      l0b0  \n",
       "3  13.963803  12.583215 -18.270712 -2.257165 -0.956019      l0b0  \n",
       "4  13.177802  12.001276 -30.508786 -0.065583 -1.574057      l0b0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a copy of the master dataframe to modify with ffp parameters\n",
    "df_ffps = df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inject_ffp_params(df_ffps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zams_mass</th>\n",
       "      <th>mass</th>\n",
       "      <th>px</th>\n",
       "      <th>py</th>\n",
       "      <th>pz</th>\n",
       "      <th>vx</th>\n",
       "      <th>vy</th>\n",
       "      <th>vz</th>\n",
       "      <th>age</th>\n",
       "      <th>popid</th>\n",
       "      <th>...</th>\n",
       "      <th>ubv_K</th>\n",
       "      <th>ubv_U</th>\n",
       "      <th>ubv_I</th>\n",
       "      <th>ubv_B</th>\n",
       "      <th>ubv_V</th>\n",
       "      <th>ubv_R</th>\n",
       "      <th>vr</th>\n",
       "      <th>mu_b</th>\n",
       "      <th>mu_lcosb</th>\n",
       "      <th>bin_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>189143</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>7.160008</td>\n",
       "      <td>0.126803</td>\n",
       "      <td>-0.126787</td>\n",
       "      <td>167.882674</td>\n",
       "      <td>256.203615</td>\n",
       "      <td>-155.728270</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>168.009958</td>\n",
       "      <td>-4.581879</td>\n",
       "      <td>7.539078</td>\n",
       "      <td>l1b1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189144</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>15.196527</td>\n",
       "      <td>0.270736</td>\n",
       "      <td>-0.272345</td>\n",
       "      <td>-7.675606</td>\n",
       "      <td>231.402495</td>\n",
       "      <td>50.598976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.619483</td>\n",
       "      <td>0.701631</td>\n",
       "      <td>3.208929</td>\n",
       "      <td>l1b1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189145</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8.112759</td>\n",
       "      <td>0.143944</td>\n",
       "      <td>-0.144131</td>\n",
       "      <td>154.171229</td>\n",
       "      <td>-171.403336</td>\n",
       "      <td>-21.046850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154.124665</td>\n",
       "      <td>-0.545463</td>\n",
       "      <td>-4.453540</td>\n",
       "      <td>l1b1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189146</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>9.592876</td>\n",
       "      <td>0.168138</td>\n",
       "      <td>-0.170320</td>\n",
       "      <td>-379.390715</td>\n",
       "      <td>-101.690067</td>\n",
       "      <td>-235.109930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-379.348947</td>\n",
       "      <td>-5.167431</td>\n",
       "      <td>-2.231358</td>\n",
       "      <td>l1b1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189147</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4.779132</td>\n",
       "      <td>0.083884</td>\n",
       "      <td>-0.084865</td>\n",
       "      <td>-121.883350</td>\n",
       "      <td>373.725632</td>\n",
       "      <td>-40.571841</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-121.756291</td>\n",
       "      <td>-1.790666</td>\n",
       "      <td>16.480960</td>\n",
       "      <td>l1b1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        zams_mass   mass         px        py        pz          vx  \\\n",
       "189143      0.001  0.001   7.160008  0.126803 -0.126787  167.882674   \n",
       "189144      0.001  0.001  15.196527  0.270736 -0.272345   -7.675606   \n",
       "189145      0.001  0.001   8.112759  0.143944 -0.144131  154.171229   \n",
       "189146      0.001  0.001   9.592876  0.168138 -0.170320 -379.390715   \n",
       "189147      0.001  0.001   4.779132  0.083884 -0.084865 -121.883350   \n",
       "\n",
       "                vy          vz  age  popid  ...  ubv_K  ubv_U  ubv_I  ubv_B  \\\n",
       "189143  256.203615 -155.728270  NaN   10.0  ...    0.0    0.0    0.0    0.0   \n",
       "189144  231.402495   50.598976  NaN   10.0  ...    0.0    0.0    0.0    0.0   \n",
       "189145 -171.403336  -21.046850  NaN   10.0  ...    0.0    0.0    0.0    0.0   \n",
       "189146 -101.690067 -235.109930  NaN   10.0  ...    0.0    0.0    0.0    0.0   \n",
       "189147  373.725632  -40.571841  NaN   10.0  ...    0.0    0.0    0.0    0.0   \n",
       "\n",
       "        ubv_V  ubv_R          vr      mu_b   mu_lcosb  bin_name  \n",
       "189143    0.0    0.0  168.009958 -4.581879   7.539078      l1b1  \n",
       "189144    0.0    0.0   -7.619483  0.701631   3.208929      l1b1  \n",
       "189145    0.0    0.0  154.124665 -0.545463  -4.453540      l1b1  \n",
       "189146    0.0    0.0 -379.348947 -5.167431  -2.231358      l1b1  \n",
       "189147    0.0    0.0 -121.756291 -1.790666  16.480960      l1b1  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ffps.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mbol</th>\n",
       "      <th>grav</th>\n",
       "      <th>feh</th>\n",
       "      <th>age</th>\n",
       "      <th>teff</th>\n",
       "      <th>exbv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188417</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188418</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188419</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188420</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188421</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189143</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189144</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189145</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189146</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189147</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1556 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        mbol  grav  feh  age  teff  exbv\n",
       "188417   NaN   NaN  NaN  NaN   NaN   NaN\n",
       "188418   NaN   NaN  NaN  NaN   NaN   NaN\n",
       "188419   NaN   NaN  NaN  NaN   NaN   NaN\n",
       "188420   NaN   NaN  NaN  NaN   NaN   NaN\n",
       "188421   NaN   NaN  NaN  NaN   NaN   NaN\n",
       "...      ...   ...  ...  ...   ...   ...\n",
       "189143   NaN   NaN  NaN  NaN   NaN   NaN\n",
       "189144   NaN   NaN  NaN  NaN   NaN   NaN\n",
       "189145   NaN   NaN  NaN  NaN   NaN   NaN\n",
       "189146   NaN   NaN  NaN  NaN   NaN   NaN\n",
       "189147   NaN   NaN  NaN  NaN   NaN   NaN\n",
       "\n",
       "[1556 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See how the original dataframe treats PBHs for comparison\n",
    "df.loc[df['rem_id']==104][['mbol', 'grav', 'feh', 'age', 'teff', 'exbv']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to set t_eff (temp), all ubvs and ztfs (photometry) = 0, set velocities: vx,vy,vz. set positions: px,pv,pz, rad, glat, glon. Assign new population id popid, sample mass from distribution (zams_mass vs mass are always almost the same it seems)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write our custom ffp output h5 file to be read by pop_syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_long_bins = df_ffps['bin_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ignored_keys(file_path = 'example_ffp.h5'):\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        add_pbh = np.array(f['add_pbh'])\n",
    "        lat_bin_edges = np.array(f['lat_bin_edges'])\n",
    "        long_bin_edges = np.array(f['long_bin_edges'])\n",
    "    return add_pbh, lat_bin_edges, long_bin_edges\n",
    "\n",
    "def write_ffp_h5(df_combined: pd.DataFrame, output_path: str = 'modified_ffp.h5'):\n",
    "    '''\n",
    "    #todo \n",
    "    Writes the input dataframe (combined df of pbh-injected pop_syn and our ffp version) to a h5 file in the appropriate format\n",
    "    for PopSyCLE to calculate the events\n",
    "    '''\n",
    "    # keys_to_write = ['add_pbh', 'l0b0', 'l0b1', 'l1b0', 'l1b1', 'lat_bin_edges', 'long_bin_edges']\n",
    "    add_pbh, lat_bin_edges, long_bin_edges = get_ignored_keys()\n",
    "    with h5py.File(output_path, 'w') as f:\n",
    "        f.create_dataset('add_pbh', data=add_pbh)\n",
    "        f.create_dataset('lat_bin_edges', data=lat_bin_edges)\n",
    "        f.create_dataset('long_bin_edges', data=long_bin_edges)\n",
    "        for bin in lat_long_bins:\n",
    "            df_bin = df_combined.loc[df_combined['bin_name'] == bin]\n",
    "            #add dataset but exclude bin number since we added this to begin with\n",
    "            df_vals = np.array(df_bin.values[:,:-1])\n",
    "            # df_tuple = tuple(tuple(row) for row in df_vals)\n",
    "            f.create_dataset(bin, data=df_vals, dtype=np.float32)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Can't write data (no appropriate function for conversion path)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m write_ffp_h5(df_ffps, \u001b[39m'\u001b[39;49m\u001b[39mmodified_ffp.h5\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[8], line 25\u001b[0m, in \u001b[0;36mwrite_ffp_h5\u001b[0;34m(df_combined, output_path)\u001b[0m\n\u001b[1;32m     23\u001b[0m df_vals \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(df_bin\u001b[39m.\u001b[39mvalues[:,:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m     24\u001b[0m \u001b[39m# df_tuple = tuple(tuple(row) for row in df_vals)\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m f\u001b[39m.\u001b[39;49mcreate_dataset(\u001b[39mbin\u001b[39;49m, data\u001b[39m=\u001b[39;49mdf_vals, dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mfloat32)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/h5py/_hl/group.py:183\u001b[0m, in \u001b[0;36mGroup.create_dataset\u001b[0;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[1;32m    180\u001b[0m         parent_path, name \u001b[39m=\u001b[39m name\u001b[39m.\u001b[39mrsplit(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m    181\u001b[0m         group \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequire_group(parent_path)\n\u001b[0;32m--> 183\u001b[0m dsid \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39;49mmake_new_dset(group, shape, dtype, data, name, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    184\u001b[0m dset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mDataset(dsid)\n\u001b[1;32m    185\u001b[0m \u001b[39mreturn\u001b[39;00m dset\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/h5py/_hl/dataset.py:168\u001b[0m, in \u001b[0;36mmake_new_dset\u001b[0;34m(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, dapl, efile_prefix, virtual_prefix, allow_unknown_filter, rdcc_nslots, rdcc_nbytes, rdcc_w0)\u001b[0m\n\u001b[1;32m    165\u001b[0m dset_id \u001b[39m=\u001b[39m h5d\u001b[39m.\u001b[39mcreate(parent\u001b[39m.\u001b[39mid, name, tid, sid, dcpl\u001b[39m=\u001b[39mdcpl, dapl\u001b[39m=\u001b[39mdapl)\n\u001b[1;32m    167\u001b[0m \u001b[39mif\u001b[39;00m (data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data, Empty)):\n\u001b[0;32m--> 168\u001b[0m     dset_id\u001b[39m.\u001b[39;49mwrite(h5s\u001b[39m.\u001b[39;49mALL, h5s\u001b[39m.\u001b[39;49mALL, data)\n\u001b[1;32m    170\u001b[0m \u001b[39mreturn\u001b[39;00m dset_id\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5d.pyx:280\u001b[0m, in \u001b[0;36mh5py.h5d.DatasetID.write\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_proxy.pyx:114\u001b[0m, in \u001b[0;36mh5py._proxy.dset_rw\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Can't write data (no appropriate function for conversion path)"
     ]
    }
   ],
   "source": [
    "write_ffp_h5(df_ffps, 'modified_ffp.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['add_pbh', 'l0b0', 'l0b1', 'l1b0', 'l1b1', 'lat_bin_edges', 'long_bin_edges']>\n"
     ]
    }
   ],
   "source": [
    "file_path = 'example_ffp.h5'\n",
    "with h5py.File(file_path, 'r') as f:\n",
    "    print(f.keys())\n",
    "    dat1 = np.array(f['l0b0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['add_pbh', 'l0b0', 'lat_bin_edges', 'long_bin_edges']>\n"
     ]
    }
   ],
   "source": [
    "file_path = 'modified_ffp.h5'\n",
    "with h5py.File(file_path, 'r') as f:\n",
    "    print(f.keys())\n",
    "    dat2 = np.array(f['l0b0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.827383041381836"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat1[0]['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = dat1.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat3 = np.array([dat2[i,:] for i in range(len(phys_keys)-1)], dtype=dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 31)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat3[0][0].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try again just following what's done in synthetic.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np.ones(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_ffp_mass(N_ffps: int) -> np.ndarray:\n",
    "    '''\n",
    "    This is a dummy function currently. Will want to sample some distribution of masses for the ffps.\n",
    "    For now, return an array of length N_ffps with fixed mass value in units of solar masses\n",
    "    '''\n",
    "\n",
    "    #Jupiter is about 1e-3 solar masses\n",
    "    return np.ones(N_ffps) * 1e-3\n",
    "\n",
    "def set_ffp_masses(ffp_arr: np.ndarray) -> None:\n",
    "    '''\n",
    "    Modifies the input dataframe to overwrite the masses of the ffps.\n",
    "    '''\n",
    "    N_objects = ffp_arr.shape[0]\n",
    "    masses = sample_ffp_mass(N_objects)\n",
    "    ffp_arr['mass'] = masses\n",
    "    #PopSyCLE sets Zero age main sequence mass,zams_mass, equal to mass for PBHs. \n",
    "    #Following this convention for ffps\n",
    "    ffp_arr['zams_mass'] = masses\n",
    "\n",
    "\n",
    "def set_ffp_photometry(ffp_arr: np.ndarray) -> None:\n",
    "    '''\n",
    "    Modifies the input dataframe to overwrite the photometry of the ffps.\n",
    "    '''\n",
    "    N_objects = ffp_arr.shape[0]\n",
    "    photometry_ffps = np.zeros(N_objects)\n",
    "\n",
    "    ffp_arr['ubv_J'] = photometry_ffps\n",
    "    ffp_arr['ubv_H'] = photometry_ffps\n",
    "    ffp_arr['ubv_K'] = photometry_ffps\n",
    "    ffp_arr['ubv_U'] = photometry_ffps\n",
    "    ffp_arr['ubv_I'] = photometry_ffps\n",
    "    ffp_arr['ubv_B'] = photometry_ffps\n",
    "    ffp_arr['ubv_V'] = photometry_ffps\n",
    "    ffp_arr['ubv_R'] = photometry_ffps\n",
    "\n",
    "def set_ffp_rem_id(ffp_arr: np.ndarray) -> None:\n",
    "    '''\n",
    "    Modifies the input dataframe to overwrite the remnant id of the ffps.\n",
    "    '''\n",
    "    N_objects = ffp_arr.shape[0]\n",
    "    #pbhs are highest remnant id implemented in popsycle so far so set ffps to 105\n",
    "    rem_ids = np.ones(N_objects) * 105\n",
    "    ffp_arr['rem_id'] = rem_ids\n",
    "\n",
    "def set_ffp_pop_id(ffp_arr: np.ndarray) -> None:\n",
    "    '''\n",
    "    Modifies the input dataframe to overwrite the pop id of the ffps.\n",
    "    Set it to 10 since this is what is done for PBHs\n",
    "    '''\n",
    "    N_objects = ffp_arr.shape[0]\n",
    "    #Population ID (e.g. Disk, Halo, Bulge. See https://galaxia.sourceforge.net/Galaxia3pub.html for details) 'popid'.\n",
    "    pop_ids = np.ones(N_objects) * 10\n",
    "\n",
    "def set_ffp_misc(ffp_arr: np.ndarray) -> None:\n",
    "    '''\n",
    "    Modifies the input dataframe to overwrite some miscilanious attributes of the ffps\n",
    "    that are not relevant for us. Set them to NaNs (this is what is done for PBHs I believe)\n",
    "    '''\n",
    "\n",
    "    # Bolometric magnitude: mbol, \n",
    "    # Surface gravity: grav,\n",
    "    # Metalicity: feh,\n",
    "    # log(age/yr): 'age',\n",
    "    # Effective temperature: teff\n",
    "    # Galactic Extinsion 'exbv'\n",
    "\n",
    "\n",
    "    N_objects = ffp_arr.shape[0]\n",
    "    misc_ffps_nans = np.full(N_objects, np.NaN)\n",
    "   \n",
    "    ffp_arr['mbol'] = misc_ffps_nans\n",
    "    ffp_arr['grav'] = misc_ffps_nans\n",
    "    ffp_arr['feh'] = misc_ffps_nans\n",
    "    ffp_arr['age'] = misc_ffps_nans\n",
    "    ffp_arr['teff'] = misc_ffps_nans\n",
    "    ffp_arr['exbv'] = misc_ffps_nans\n",
    "\n",
    "\n",
    "def inject_ffp_params(ffp_arr: np.ndarray) -> None:\n",
    "    '''\n",
    "    Modifies the input numpy array to overwrite all relevant parameters for ffps\n",
    "    '''\n",
    "    set_ffp_masses(ffp_arr)\n",
    "    set_ffp_photometry(ffp_arr)\n",
    "    set_ffp_rem_id(ffp_arr)\n",
    "    set_ffp_misc(ffp_arr)\n",
    "    set_ffp_pop_id(ffp_arr)\n",
    "\n",
    "    #todo\n",
    "    #Heliocentric velocities (in km/s): 'vx', 'vy', 'vz',\n",
    "    #Radial velocity and proper motions: 'vr', 'mu_b', 'mu_lcosb'\n",
    "    # Galactic positions 'rad', 'glat', 'glon'\n",
    "    # Heliocentric positions: 'px', 'py', 'pz', \n",
    "    # positions related by:\n",
    "    # comp_helio = synthetic.galactic_to_heliocentric(\n",
    "    #             comp_dict[\"rad\"], comp_dict[\"glat\"], comp_dict[\"glon\"]\n",
    "    #         )\n",
    "    #         comp_dict[\"px\"], comp_dict[\"py\"], comp_dict[\"pz\"] = comp_helio\n",
    "    # Object number within given bin: obj_id - Don't think we care about this but should revisit later - obj_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_file = 'example_ffp_copy.h5'\n",
    "output_hdf5_file = 'modified_ffp.h5'\n",
    "\n",
    "no_ffp_hdf5_file = h5py.File(hdf5_file, \"r\")\n",
    "ffp_hdf5_file = h5py.File(output_hdf5_file, \"w\")\n",
    "\n",
    "key_list = list(no_ffp_hdf5_file)\n",
    "key_list = [key for key in key_list if key not in ignored_keys]\n",
    "\n",
    "hdf5_dset_names = no_ffp_hdf5_file[key_list[0]][:].dtype.names\n",
    "comp_dtype = synthetic._generate_comp_dtype(hdf5_dset_names)\n",
    "\n",
    "#If we want to compare to no pbhs, set this to false and use non-pbh h5 as 'hdf5_file'\n",
    "ffp_hdf5_file[\"add_pbh\"] = True\n",
    "\n",
    "lat_bin = no_ffp_hdf5_file[\"lat_bin_edges\"][:]\n",
    "long_bin = no_ffp_hdf5_file[\"long_bin_edges\"][:]\n",
    "\n",
    "for idx, key in enumerate(key_list):\n",
    "    key_data = no_ffp_hdf5_file[key][:]\n",
    "    #copy the stars in this bin (assuming 1 ffp per star implicitly)\n",
    "    ffp_data_in_key = copy.deepcopy(key_data)\n",
    "    #modify the copy to use the ffp params\n",
    "    inject_ffp_params(ffp_data_in_key)\n",
    "    combined_data = np.hstack((key_data, ffp_data_in_key))\n",
    "\n",
    "    _ = ffp_hdf5_file.create_dataset(\n",
    "        key, shape=(combined_data.shape[0],), dtype=comp_dtype, data=combined_data\n",
    "    )\n",
    "    \n",
    "_ = ffp_hdf5_file.create_dataset(\"lat_bin_edges\", (len(lat_bin), 1), data=lat_bin)\n",
    "_ = ffp_hdf5_file.create_dataset(\"long_bin_edges\", (len(lat_bin), 1), data=long_bin)\n",
    "\n",
    "no_ffp_hdf5_file.close()\n",
    "ffp_hdf5_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['add_pbh', 'l0b0', 'l0b1', 'l1b0', 'l1b1', 'lat_bin_edges', 'long_bin_edges']>\n"
     ]
    }
   ],
   "source": [
    "file_path = 'modified_ffp.h5'\n",
    "with h5py.File(file_path, 'r') as f:\n",
    "    print(f.keys())\n",
    "    dat2 = np.array(f['l0b0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's try and calculate events for this new population file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make obs_time and area small for testing\n",
    "mock_roman_params = {\"fdm\": 1.0, \n",
    "                     \"pbh_mass\":30, \n",
    "                     \"v_esc\":550, \n",
    "                     \"rho_0\":0.0093, \n",
    "                     \"r_s\": 18.6, \n",
    "                     \"r_max\":16.6 , \n",
    "                     \"gamma\": 1.0, \n",
    "                    #  \"obs_time\":1825, \n",
    "                     \"obs_time\":18, \n",
    "                     \"cadence\":3, \n",
    "                     \"blend_rad\": 0.09, \n",
    "                     \"longitude\": 1.00, \n",
    "                     \"latitude\": -1.03, \n",
    "                    #  \"area\": 0.16,\n",
    "                     \"area\": 0.0016,\n",
    "                     \"BH_kick_speed_mean\": 100,\n",
    "                     \"NS_kick_speed_mean\": 350\n",
    "                     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set to Roman Params from paper\n",
    "synthetic.calc_events(hdf5_file = 'modified_ffp.h5', \n",
    "                      output_root2 = 'modified_ffp_output', \n",
    "                      radius_cut = 2,\n",
    "                      obs_time = mock_roman_params[\"obs_time\"], \n",
    "                      n_obs = int(mock_roman_params[\"obs_time\"]/mock_roman_params[\"cadence\"]), \n",
    "                      theta_frac = 2, \n",
    "                      blend_rad = mock_roman_params[\"blend_rad\"], \n",
    "                      overwrite = False, \n",
    "                      n_proc = 7,) #adjust based on your number of cores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
